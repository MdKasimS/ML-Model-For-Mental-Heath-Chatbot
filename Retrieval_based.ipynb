{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5y_I0O-5RMh"
   },
   "source": [
    "## Loading data and preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YR-ilUaKO1mR"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import string\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten, Conv1D, MaxPooling1D, SimpleRNN, GRU, LSTM, LSTM, Input, Embedding, TimeDistributed, Flatten, Dropout,Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zo9OE78qO9Pe"
   },
   "outputs": [],
   "source": [
    "# download dependencies \n",
    "\n",
    "# uncomment if running for the first time\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EnLqRE6uS2Hb",
    "outputId": "470b6d1a-7f26-4d8e-b60c-48e3db2e2991"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('/MentalHealthChatbot/models/Dataset/mentalhealth.json') as file:\n",
    "  data = json.load(file)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHalec2-OgjC"
   },
   "outputs": [],
   "source": [
    "# convert to dataframes \n",
    " \n",
    "def frame_data(feat_1,feat_2,is_pattern):\n",
    "  is_pattern = is_pattern\n",
    "  df = pd.DataFrame(columns=[feat_1,feat_2])\n",
    "  for intent in data['intents']:\n",
    "    if is_pattern:\n",
    "      for pattern in intent['patterns']:\n",
    "        w = pattern\n",
    "        df_to_append = pd.Series([w,intent['tag']], index = df.columns)\n",
    "        df = df.append(df_to_append,ignore_index=True)\n",
    "    else:\n",
    "      for response in intent['responses']:\n",
    "        w = response\n",
    "        df_to_append = pd.Series([w,intent['tag']], index = df.columns)\n",
    "        df = df.append(df_to_append,ignore_index=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "nzHe4LRwS7KL",
    "outputId": "ef19fb8a-89f4-42ea-e294-e32758e746ea"
   },
   "outputs": [],
   "source": [
    "df1 = frame_data('questions','labels',True)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBK6Wzi-S7GW",
    "outputId": "861808e1-063b-4d1f-b0d7-dd5564e2ee30"
   },
   "outputs": [],
   "source": [
    "# no of patterns\n",
    "\n",
    "(df1.labels.value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "me9oCoFmS7EI",
    "outputId": "730658df-9755-4b6f-fba7-68904e0f1ae0"
   },
   "outputs": [],
   "source": [
    "df2 = frame_data('response','labels',False)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja0_TgzN5Xya"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEVlJqEIR_ts"
   },
   "outputs": [],
   "source": [
    "# preprocessing text\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "vocab = Counter()\n",
    "labels = []\n",
    "def tokenizer(entry):\n",
    "    tokens = entry.split()\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [lemmatizer.lemmatize(w.lower()) for w in tokens]\n",
    "    tokens = [word.lower() for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "def remove_stop_words(tokenizer,df,feature):\n",
    "    doc_without_stopwords = []\n",
    "    for entry in df[feature]:\n",
    "        tokens = tokenizer(entry)\n",
    "        joblib.dump(tokens,'tokens.pkl')\n",
    "        doc_without_stopwords.append(' '.join(tokens))\n",
    "    df[feature] = doc_without_stopwords\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jt61ZCG9UWN0"
   },
   "outputs": [],
   "source": [
    "def create_vocab(tokenizer,df,feature):\n",
    "    for entry in df[feature]:\n",
    "        tokens = tokenizer(entry)   \n",
    "        vocab.update(tokens)\n",
    "    joblib.dump(vocab,'vocab.pkl')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emdwHIQcUWJ-"
   },
   "outputs": [],
   "source": [
    "create_vocab(tokenizer,df1,'questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbK9OeYY0iWo",
    "outputId": "e058ceab-cdd4-4b40-eb08-ad9246b607d3"
   },
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_EER8ZWkpJU",
    "outputId": "0b272597-4ea5-44dd-f37a-2c7df0e8731a"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2S6fc7iV5Fl",
    "outputId": "23324a36-3505-45b6-a5cc-2e48ac3da410"
   },
   "outputs": [],
   "source": [
    "df1.groupby(by='labels',as_index=False).first()['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flmw4NGyR_o1",
    "outputId": "63f1c0f6-4587-4093-ed72-f3213e5449e4"
   },
   "outputs": [],
   "source": [
    "# test_list contains the first element of questions\n",
    "\n",
    "test_list = list(df1.groupby(by='labels',as_index=False).first()['questions'])\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MNtMUqJQUs9U",
    "outputId": "033574e0-71f2-411b-8bc6-6ae9557fd3c5"
   },
   "outputs": [],
   "source": [
    "# indices of the testing dataset\n",
    "\n",
    "test_index = []\n",
    "for i,_ in enumerate(test_list):\n",
    "    idx = df1[df1.questions == test_list[i]].index[0]\n",
    "    test_index.append(idx)\n",
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Reko6L-LUs6e",
    "outputId": "30ace821-537d-4573-980b-787511baabf6"
   },
   "outputs": [],
   "source": [
    "# train indices are the all indices minus the testing indices \n",
    "\n",
    "train_index = [i for i in df1.index if i not in test_index]\n",
    "train_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-ksA3SrUs3a"
   },
   "outputs": [],
   "source": [
    "def convert_seq(df,feature):\n",
    "#     text = ' '.join(list(vocab.keys()))\n",
    "    t = Tokenizer()\n",
    "    entries = [entry for entry in df[feature]]\n",
    "    print(entries)\n",
    "    print('----')\n",
    "    t.fit_on_texts(entries)\n",
    "    joblib.dump(t,'tokenizer_t.pkl')   # why a pkl file\n",
    "    vocab_size = len(t.word_index) +1 # +1 for oov \n",
    "    print(t.word_index)\n",
    "    entries = [entry for entry in df[feature]]\n",
    "    max_length = max([len(s.split()) for s in entries])\n",
    "    print('----')\n",
    "    print(\"max length of string is : \",max_length)\n",
    "    print('----')\n",
    "    encoded = t.texts_to_sequences(entries)\n",
    "    print(encoded)\n",
    "    padded = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
    "    print('----')\n",
    "    print(padded)\n",
    "    return padded, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjFFIlul53UZ"
   },
   "source": [
    "**fit_on_texts** updates internal vocabulary based on a list of texts. This method creates the vocabulary index based on word frequency. 0 is reserved for padding. So lower integer means more frequent word (often the first few are stop words because they appear a lot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5a_RLov7R2s"
   },
   "source": [
    "Now that we have a vocabulary of words in the dataset, **each of the patterns can be encoded into numerical features for modeling, using any of the common text encoding techniques—count vectorizer**, term frequency-inverse document frequency (TF-IDF), hashing, etc.\n",
    "\n",
    "Using TensorFlow.Keras text_to_sequence, we can **encode each pattern corpus to vectorize a text corpus by turning each text into either a sequence of integers** (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count which is based on TF-IDF. The resulting vectors will be post-padded with zeros so as to equal the length of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GP07TFsDUs0e",
    "outputId": "7c2ace6d-31ad-464f-edb9-e0e606ad1f82"
   },
   "outputs": [],
   "source": [
    "X,vocab_size = convert_seq(df1,'questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjqSgtug5uSU"
   },
   "outputs": [],
   "source": [
    "with open('tokenizer_t.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ww0VWLGV6WDo",
    "outputId": "590e3660-78a5-4e56-fac3-3585f7a55cae"
   },
   "outputs": [],
   "source": [
    "data.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TKUtsd851W4",
    "outputId": "a5e422af-11a5-4bdb-ddfc-f0784fa84e4f"
   },
   "outputs": [],
   "source": [
    "data.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gExivERw6WdD",
    "outputId": "9f90dcea-abdc-4aff-cd32-e27616f2ddbe"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bimUOhFb6Y_9",
    "outputId": "91159b95-22dd-4f6f-a8bd-17d10ebf9c0f"
   },
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cKWHDabXLg_"
   },
   "outputs": [],
   "source": [
    "df_encoded = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "id": "wfjo-4088OnX",
    "outputId": "d6f6a60e-7f8e-40f5-ca50-69062a34d4fa"
   },
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "Dje2hCaJ8IPc",
    "outputId": "3a3d5190-13bc-4118-f953-07d0ed5dd3de"
   },
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "3Uu_JiN5XLdt",
    "outputId": "d83accbd-8cfe-4b46-9cc4-6b39a218172f"
   },
   "outputs": [],
   "source": [
    "df_encoded['labels'] = df1.labels\n",
    "df_encoded.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "id": "heGzmZM3XS4J",
    "outputId": "ed09e08b-e76f-48c2-da63-99e09df7e653"
   },
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxyYd8LvXSwB",
    "outputId": "32c053a6-2222-4c09-d36d-c2ace77ed244"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable_enc = LabelEncoder()\n",
    "\n",
    "# encoding the labels\n",
    "\n",
    "labl = lable_enc.fit_transform(df_encoded.labels)\n",
    "labl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EL0qCx9e_9Jm",
    "outputId": "e7ac0310-b592-4f3d-920f-acefda9bdeba"
   },
   "outputs": [],
   "source": [
    "len(labl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMC_1ZukXiDL",
    "outputId": "cd90cd74-9007-4df0-d558-f07cd0e9db15"
   },
   "outputs": [],
   "source": [
    "mapper = {}\n",
    "for index,key in enumerate(df_encoded.labels):\n",
    "    if key not in mapper.keys():\n",
    "        mapper[key] = labl[index]\n",
    "mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3myx7GaAI5Q"
   },
   "source": [
    "Repeat the same for df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "4nCk2oQbXh_X",
    "outputId": "7fa8a86a-9bb1-40c5-9bbb-d08e0472e4f1"
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "5mqpR_GuMPrc",
    "outputId": "4f2363e2-0a7b-45cf-b527-e4c108400f08"
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "cR7qqxoeXh8w",
    "outputId": "bfb288a2-e061-4928-9b8b-3a1e20d69fa2"
   },
   "outputs": [],
   "source": [
    "df2.labels = df2.labels.map(mapper).astype({'labels': 'int32'})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ixZCvNZXn4g"
   },
   "outputs": [],
   "source": [
    "df2.to_csv('response.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "hIjUTKNvAfao",
    "outputId": "a084e1eb-af7a-49bd-c664-4453abdaf6c0"
   },
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIyITJXtAkHZ",
    "outputId": "59a4c91e-e020-48ad-e2d4-44587dba3534"
   },
   "outputs": [],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdAynG8hAmUF",
    "outputId": "aff7c007-10fe-4482-d4fa-ff03e1c283d1"
   },
   "outputs": [],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KWZh9SUXtwA"
   },
   "outputs": [],
   "source": [
    "train = df_encoded.loc[train_index]\n",
    "test = df_encoded.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb9aSpfs7NSN"
   },
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "AcAZpSdmBYSx",
    "outputId": "001562f0-5172-4d9d-a1bc-5c57b6b84084"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "epPEROQGBlsm",
    "outputId": "20e37b06-0375-4ce9-82d2-0a4cb57bec53"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1ZYcCJFmQfg",
    "outputId": "3726982d-8103-4c01-c4ac-cb1cc22665d5"
   },
   "outputs": [],
   "source": [
    "train.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E46URbzfmTLE",
    "outputId": "6f923aae-c043-43e7-d209-94ff07b7881e"
   },
   "outputs": [],
   "source": [
    "test.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "PcbjQwN-RQui",
    "outputId": "0eebccd7-fa8c-4bdf-cedc-c8bd68ce066d"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2syG8OIXtsl"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['labels'],axis=1)\n",
    "y_train = train.labels\n",
    "X_test = test.drop(columns=['labels'],axis=1)\n",
    "y_test = test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "t0jjLEnErX9h",
    "outputId": "e444ff00-cc70-405f-ebdf-61fee0a57de7"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cSOF7OeXtqJ"
   },
   "outputs": [],
   "source": [
    "y_train =pd.get_dummies(y_train).values\n",
    "y_test =pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "lG_4kPvW96KK",
    "outputId": "953e0046-fa67-4b93-8c56-af3ecde9abb5"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "bZyNYXsjfY2y",
    "outputId": "6e462b54-5e0c-45d6-a911-e361be113c6c"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWFWgav5B-pH",
    "outputId": "cb4ed15f-5382-476e-a2f8-cf55f306ae84"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvhKy5u6mM0k",
    "outputId": "2c3889ca-337e-4cad-be92-984234f8ed31"
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPZDWFkBmOdx",
    "outputId": "5ae5e495-7ca3-4f7c-8ed7-4d6af7a3413b"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_urYiDyXtn5",
    "outputId": "bd674f43-900b-410a-d670-309243eac8ae"
   },
   "outputs": [],
   "source": [
    "y_train[0].shape,y_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jMrfnwKX1DC",
    "outputId": "832af3f7-4495-4c08-b90c-c97eff02dabf"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yf1it_OmmurY",
    "outputId": "d3e15ac4-58c1-4ce6-d228-7b380c988c78"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJHi-DiIX0_D"
   },
   "outputs": [],
   "source": [
    "max_length = X_train.shape[1]\n",
    "output = 16                  # no of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v72uEhyGCk8Z"
   },
   "source": [
    "Reference for the model below:\n",
    "\n",
    "*   https://keras.io/api/callbacks/model_checkpoint/\n",
    "*   https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtCFWykAX08b"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',patience=10) #patience : number of epochs with no improvement after which training will be stopped\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model-v1.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "callbacks = [early_stopping,checkpoint,reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65wJtH4MG0It"
   },
   "source": [
    "References : \n",
    "* Word embeddings - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "* 2D CNN when we have 3D features, such as RGB - \n",
    "https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/\n",
    "* Pooling layers reduce the size of the representation to speed up the computation and make features robust\n",
    "* Add a \"flatten\" layer which prepares a vector for the fully connected layers, for example using Sequential.add(Flatten()) -  \n",
    "https://missinglink.ai/guides/keras/using-keras-flatten-operation-cnn-models-code-examples/\n",
    "* Dense layer - A fully connected layer also known as the dense layer, in which the results of the convolutional layers are fed through one or more neural layers to generate a prediction\n",
    "* Activation functions - https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zfZy2tABMkl"
   },
   "source": [
    "## Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uwe7aPetEi3"
   },
   "source": [
    "* Why use embedding layer before RNN/ LSTM layer -\n",
    "https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12\n",
    "* Learning curves - https://www.dataquest.io/blog/learning-curves-machine-learning/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOvE1ucyMcUZ"
   },
   "outputs": [],
   "source": [
    "def define_model1(vocab_size, max_length):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Embedding(vocab_size,100, input_length=max_length))\n",
    "    model1.add(SimpleRNN(100))\n",
    "    model1.add(Dense(10, activation='softmax'))   \n",
    "    \n",
    "    model1.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    # summarize defined model\n",
    "    model1.summary()\n",
    "    plot_model(model1, to_file='model_1.png', show_shapes=True)\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Toir2G_NNEsX",
    "outputId": "98112820-925a-41a4-eea9-28ac0da91f8d"
   },
   "outputs": [],
   "source": [
    "model1 = define_model1(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTFpfCkUNEpg",
    "outputId": "9191868b-6612-4c08-c99b-1babf28333bb"
   },
   "outputs": [],
   "source": [
    "history1 = model1.fit(X_train, y_train, epochs=10, verbose=1,validation_data=(X_test,y_test),callbacks=callbacks)#,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "k0I_FjV6mDQR",
    "outputId": "647955ed-729d-432f-b78f-52d08bf8798d"
   },
   "outputs": [],
   "source": [
    "# Learning curves \n",
    "\n",
    "acc = history1.history['accuracy']\n",
    "val_acc = history1.history['val_accuracy']\n",
    "loss=history1.history['loss']\n",
    "val_loss=history1.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdIDkqyABJbr"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sR_Z8kDX8VD"
   },
   "outputs": [],
   "source": [
    "def define_model2(vocab_size, max_length):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Embedding(vocab_size,300, input_length=max_length))\n",
    "    model2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "    model2.add(MaxPooling1D(pool_size = 4))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(32, activation='relu'))\n",
    "    model2.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model2.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    # summarize defined model\n",
    "    model2.summary()\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1ePmE7PX8R0",
    "outputId": "94070aba-3771-4325-e72a-27f8f9475f7d"
   },
   "outputs": [],
   "source": [
    "model2 = define_model2(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnC_x02JX8Pd",
    "outputId": "93ae2b41-a447-4a9d-fa8b-952ceea4b9f6"
   },
   "outputs": [],
   "source": [
    "history = model2.fit(X_train, y_train, epochs=15, verbose=1,validation_data=(X_test,y_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "SMNZHhfqYEQ9",
    "outputId": "0c81da43-c58a-419d-b477-9afb5cb5c262"
   },
   "outputs": [],
   "source": [
    "# Learning curves \n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_PRZPplHqmV"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-T3A0-TWmDS8"
   },
   "outputs": [],
   "source": [
    "def define_model3(vocab_size, max_length):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Embedding(vocab_size,300, input_length=max_length))\n",
    "    model3.add(LSTM(500))\n",
    "    model3.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model3.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    # summarize defined model\n",
    "    model3.summary()\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNtO1edjHxt6",
    "outputId": "649205f4-53fa-4ba1-909b-827dab404f80"
   },
   "outputs": [],
   "source": [
    "model3 = define_model3(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGq3NSaJCoJg",
    "outputId": "8bbbeb09-6b9c-45c8-ef4e-38beb1ffa860"
   },
   "outputs": [],
   "source": [
    "history = model3.fit(X_train, y_train, epochs=15, verbose=1,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "36X8FbbgOhTf",
    "outputId": "d559e43f-df22-46de-a7a1-ec3c9cab5e07"
   },
   "outputs": [],
   "source": [
    "# Learning curves \n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBmXCUoUct-Y"
   },
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzIyloY3cyoD"
   },
   "outputs": [],
   "source": [
    "def define_model3(vocab_size, max_length):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Embedding(vocab_size,300, input_length=max_length))\n",
    "    model3.add(GRU(500))\n",
    "    model3.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model3.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    # summarize defined model\n",
    "    model3.summary()\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEXaR-g4cylS",
    "outputId": "b8071e06-098e-4878-fae7-84a628aa0673"
   },
   "outputs": [],
   "source": [
    "model3 = define_model3(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49hqm9sWc1ED",
    "outputId": "b5da6e36-1690-4bd7-9f26-4706bf58a724"
   },
   "outputs": [],
   "source": [
    "history = model3.fit(X_train, y_train, epochs=15, verbose=1,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "xDKC13iBc3Bw",
    "outputId": "fb4ff52f-419b-4d2f-d781-446632aa796d"
   },
   "outputs": [],
   "source": [
    "# Learning curves \n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ2romsAsshs"
   },
   "source": [
    "## BiLSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b02HsFGVs0WV"
   },
   "outputs": [],
   "source": [
    "def define_model3(vocab_size, max_length):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Embedding(vocab_size,300, input_length=max_length))\n",
    "    model3.add(Bidirectional(LSTM(500)))\n",
    "    model3.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model3.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    # summarize defined model\n",
    "    model3.summary()\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4VV9MlFs1Va",
    "outputId": "2c1f7a8a-5f09-4d3c-aa1d-86adb03de019"
   },
   "outputs": [],
   "source": [
    "model3 = define_model3(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfNlWQazs1Sa",
    "outputId": "34d4b707-9efd-4f6f-de1c-af46e0b2950a"
   },
   "outputs": [],
   "source": [
    "history = model3.fit(X_train, y_train, epochs=10, verbose=1,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "_XGvXqCfs1Qf",
    "outputId": "45e3d1d9-1171-4f92-9a6e-53c29ff8583e"
   },
   "outputs": [],
   "source": [
    "# Learning curves \n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3I8Ykx3HGacK"
   },
   "source": [
    "Future scope -\n",
    "* embedding layer : GloVe\n",
    "* cross validation for testing\n",
    "* grid search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xL1vugJNLy5x"
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnWEw7d5TcOv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnB6-nG6SelW"
   },
   "outputs": [],
   "source": [
    "def get_text(str_text):\n",
    "    # print(str_text)\n",
    "    input_text  = [str_text]\n",
    "    df_input = pd.DataFrame(input_text,columns=['questions'])\n",
    "    df_input\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1101EozZSefs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = model2\n",
    "tokenizer_t = joblib.load('tokenizer_t.pkl')\n",
    "vocab = joblib.load('vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c51lst4wSedH"
   },
   "outputs": [],
   "source": [
    "def tokenizer(entry):\n",
    "    tokens = entry.split()\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [lemmatizer.lemmatize(w.lower()) for w in tokens]\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = [word.lower() for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FK79K154Sp4y"
   },
   "outputs": [],
   "source": [
    "def remove_stop_words_for_input(tokenizer,df,feature):\n",
    "    doc_without_stopwords = []\n",
    "    entry = df[feature][0]\n",
    "    tokens = tokenizer(entry)\n",
    "    doc_without_stopwords.append(' '.join(tokens))\n",
    "    df[feature] = doc_without_stopwords\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afJXXfckSp1u"
   },
   "outputs": [],
   "source": [
    "def encode_input_text(tokenizer_t,df,feature):\n",
    "    t = tokenizer_t\n",
    "    entry = entry = [df[feature][0]]\n",
    "    encoded = t.texts_to_sequences(entry)\n",
    "    padded = pad_sequences(encoded, maxlen=10, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVfxwXqFSpzc"
   },
   "outputs": [],
   "source": [
    "def get_pred(model,encoded_input):\n",
    "    pred = np.argmax(model.predict(encoded_input))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoq7PSF6Sea4"
   },
   "outputs": [],
   "source": [
    "def bot_precausion(df_input,pred):\n",
    "    words = df_input.questions[0].split()\n",
    "    if len([w for w in words if w in vocab])==0 :\n",
    "        pred = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVP1uNDjS1D2"
   },
   "outputs": [],
   "source": [
    "def get_response(df2,pred):\n",
    "    upper_bound = df2.groupby('labels').get_group(pred).shape[0]\n",
    "    r = np.random.randint(0,upper_bound)\n",
    "    responses = list(df2.groupby('labels').get_group(pred).response)\n",
    "    return responses[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeKrDXvxS1A9"
   },
   "outputs": [],
   "source": [
    "def bot_response(response,):\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a1AmUnKS6WW",
    "outputId": "fdee2cd3-a98f-474d-b250-548873a03c6c"
   },
   "outputs": [],
   "source": [
    "# correct response\n",
    "\n",
    "df_input = get_text(\"What does it mean to have a mental illness\")\n",
    "\n",
    "# load artifacts \n",
    "tokenizer_t = joblib.load('tokenizer_t.pkl')\n",
    "vocab = joblib.load('vocab.pkl')\n",
    "\n",
    "df_input = remove_stop_words_for_input(tokenizer,df_input,'questions')\n",
    "encode_input = encode_input_text(tokenizer_t,df_input,'questions')\n",
    "\n",
    "pred = get_pred(model1,encode_input)\n",
    "pred = bot_precausion(df_input,pred)\n",
    "\n",
    "response = get_response(df2,pred)\n",
    "bot_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hLqCtf2Su8W",
    "outputId": "45fce787-be44-4006-96b2-0d3a1e2bc785"
   },
   "outputs": [],
   "source": [
    "# wrong response\n",
    "\n",
    "df_input = get_text(\"What treatment options are available?\")\n",
    "\n",
    "#load artifacts \n",
    "tokenizer_t = joblib.load('tokenizer_t.pkl')\n",
    "vocab = joblib.load('vocab.pkl')\n",
    "\n",
    "df_input = remove_stop_words_for_input(tokenizer,df_input,'questions')\n",
    "encoded_input = encode_input_text(tokenizer_t,df_input,'questions')\n",
    "\n",
    "pred = get_pred(model1,encoded_input)\n",
    "pred = bot_precausion(df_input,pred)\n",
    "\n",
    "response = get_response(df2,pred)\n",
    "bot_response(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Retrieval based",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
